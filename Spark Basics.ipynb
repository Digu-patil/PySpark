{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb485c1",
   "metadata": {},
   "source": [
    "## Building the Spark Session\n",
    "\n",
    "- Spark Sessions help us to create a spark application which helps us to communicate with the Driver (JVM)\n",
    "- Python Code -> Spark Session -> Driver\n",
    "- This Spark Session starts the driver process, setsup the SparkContect, and establishes the bridge to the JVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b219d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version :  3.5.5\n"
     ]
    }
   ],
   "source": [
    "# Importing the Spark Session module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creating an application using the SparkSession\n",
    "\n",
    "sp = SparkSession.builder \\\n",
    "        .appName(\"Spark Basics\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Check if the application is created successfully by checking the spark appliaction version \n",
    "\n",
    "print('Spark Version : ',sp.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34087fb",
   "metadata": {},
   "source": [
    "___\n",
    "## Locally Hosted Spark UI\n",
    "- When we create a spark session it locally hosts a web ui page at http://localhost:4040/ locaiton\n",
    "- We can check all the Job statuses, DAGs, Plans here\n",
    "\n",
    "## General Deployment methods of Spark Applications\n",
    "\n",
    "||Use Case|Your Computer|Data Center Cloud|\n",
    "|---|---|---|---|\n",
    "|Local|Testing|Driver and Executor||\n",
    "|Client|Development|Driver|Executor|\n",
    "|Cluster|Prodcution||Driver and Executor|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a6c56",
   "metadata": {},
   "source": [
    "___\n",
    "## Understanding Flow of Python Code to Spark Execution\n",
    "\n",
    "```mermaid\n",
    "\n",
    "flowchart LR\n",
    "\n",
    "t1[Python Code]\n",
    "t2[\"Py4J (Bridge between Python and JVM)\"]\n",
    "t3[\"JVM\n",
    "(-Runs actual computations\n",
    "-Manages Clusters\n",
    "-Does parallel processing)\"]\n",
    "\n",
    "t1-->t2-->t3\n",
    "```\n",
    "\n",
    "### Drivers and Executors\n",
    "- Drivers and Executors are all part of the JVM\n",
    "- When running on cluster, Driver can be on a different JVM and Executors can be on a different JVM\n",
    "\n",
    "### Driver\n",
    "- Driver is a Project Manager\n",
    "- As mentioned above we create \"Spark Session\" to setup this \"Driver\" and the JVM communication channel.\n",
    "- There can be only one \"Driver\" for each Spark Session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36504c7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b4197c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f010db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f56b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
